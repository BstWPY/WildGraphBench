import os
import json
import tiktoken
import re
from pathlib import Path
from typing import Dict, List, Tuple
from collections import defaultdict
import statistics

def count_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    """
    ä½¿ç”¨tiktokenè®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼›å…è®¸æŠŠç‰¹æ®Štokenå½“æ™®é€šæ–‡æœ¬ç¼–ç 
    """
    try:
        encoding = tiktoken.encoding_for_model(model)
    except Exception:
        # æŸäº›æ¨¡å‹åä¸è¢«è¯†åˆ«æ—¶ï¼Œå›é€€åˆ° cl100k_base
        encoding = tiktoken.get_encoding("cl100k_base")

    # å…³é”®ï¼šå…³é—­ç‰¹æ®Štokenæ ¡éªŒ
    try:
        return len(encoding.encode(text, disallowed_special=()))
    except Exception:
        # å…œåº•ï¼šå»æ‰ <|...|> è¿™ç§æ ‡è®°å†ç¼–ç ï¼ˆæå°‘ç”¨åˆ°ï¼‰
        cleaned = re.sub(r"<\|[^|>]+?\|>", "", text)
        return len(encoding.encode(cleaned, disallowed_special=()))

def read_file_content(file_path: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return ""

def is_content_file(file_path: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯å†…å®¹æ–‡ä»¶ï¼ˆæ’é™¤åªæœ‰URLçš„jsonæ–‡ä»¶ï¼‰"""
    if file_path.endswith('.json') or file_path.endswith('.jsonl'):
        return False
    return file_path.endswith('.md')

def get_default_config(gpu_count: int = 8) -> Dict:
    """è·å–é»˜è®¤é…ç½®ä¿¡æ¯"""
    return {
        "gpu_config": f"0-{gpu_count-1}",
        "gpu_ids": list(range(gpu_count)),
        "ports": list(range(30060, 30060 + gpu_count)),
        "service_urls": [f"http://localhost:{port}" for port in range(30060, 30060 + gpu_count)],
        "gpu_count": gpu_count,
        "internal_ip": "localhost"
    }

def analyze_category(category_path: str, use_cleaned: bool = False) -> Dict:
    """åˆ†æå•ä¸ªç±»åˆ«çš„tokenç»Ÿè®¡
    
    Args:
        category_path: ç±»åˆ«è·¯å¾„
        use_cleaned: æ˜¯å¦ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®ï¼ˆä»raw_cleanedç›®å½•ï¼‰
    """
    category_name = os.path.basename(category_path)
    print(f"ğŸ“Š åˆ†æç±»åˆ«: {category_name}")
    
    wiki_stats = []
    total_wikis = 0
    total_references = 0
    
    # éå†ç±»åˆ«ä¸‹çš„æ‰€æœ‰wikiç›®å½•
    for wiki_item in os.listdir(category_path):
        wiki_dir = os.path.join(category_path, wiki_item)
        if not os.path.isdir(wiki_dir):
            continue
        
        total_wikis += 1
        wiki_tokens = 0
        ref_tokens = 0
        ref_count = 0
        
        print(f"  ğŸ“‚ å¤„ç†wiki: {wiki_item}")
        
        # å¤„ç†wikiä¸»æ–‡ä»¶
        for file in os.listdir(wiki_dir):
            if file.endswith('.md'):
                wiki_file_path = os.path.join(wiki_dir, file)
                content = read_file_content(wiki_file_path)
                if content:
                    tokens = count_tokens(content)
                    wiki_tokens += tokens
                    print(f"    ğŸ“„ {file}: {tokens:,} tokens")
        
        # å¤„ç†referenceç›®å½•ä¸‹çš„å‚è€ƒæ–‡ä»¶
        ref_dir = os.path.join(wiki_dir, "reference")
        if os.path.exists(ref_dir):
            if use_cleaned:
                # ä½¿ç”¨æ¸…æ´—åçš„æ–‡ä»¶
                ref_pages_dir = os.path.join(ref_dir, "reference_pages_cleaned")
                dir_label = "æ¸…æ´—åçš„å‚è€ƒæ–‡çŒ®"
            else:
                # ä½¿ç”¨åŸå§‹çš„å‚è€ƒæ–‡ä»¶
                ref_pages_dir = os.path.join(ref_dir, "reference_pages")
                dir_label = "åŸå§‹å‚è€ƒæ–‡çŒ®"
            
            if os.path.exists(ref_pages_dir):
                print(f"    ğŸ“ å¤„ç†{dir_label}ç›®å½•: {ref_pages_dir}")
                
                # è·å–æ‰€æœ‰.mdæ–‡ä»¶
                ref_files = [f for f in os.listdir(ref_pages_dir) if f.endswith('.md')]
                print(f"    ğŸ“‹ æ‰¾åˆ° {len(ref_files)} ä¸ªå‚è€ƒæ–‡çŒ®æ–‡ä»¶")
                
                for ref_file in ref_files:
                    ref_file_path = os.path.join(ref_pages_dir, ref_file)
                    content = read_file_content(ref_file_path)
                    if content:
                        tokens = count_tokens(content)
                        ref_tokens += tokens
                        ref_count += 1
                        total_references += 1
                        # print(f"      ğŸ“„ {ref_file}: {tokens:,} tokens")  # å¯é€‰ï¼šæ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„è¯¦æƒ…
                
                if ref_count > 0:
                    print(f"    ğŸ“Š {dir_label}: {ref_count} æ–‡ä»¶, {ref_tokens:,} tokens")
                else:
                    print(f"    âš ï¸  {dir_label}ç›®å½•ä¸ºç©ºæˆ–æ— æœ‰æ•ˆå†…å®¹")
            else:
                print(f"    âš ï¸  {dir_label}ç›®å½•ä¸å­˜åœ¨: {ref_pages_dir}")
        else:
            print(f"    âš ï¸  referenceç›®å½•ä¸å­˜åœ¨")
        
        # è®°å½•è¯¥wikiçš„ç»Ÿè®¡
        wiki_stats.append({
            'name': wiki_item,
            'wiki_tokens': wiki_tokens,
            'reference_tokens': ref_tokens,
            'reference_count': ref_count,
            'total_tokens': wiki_tokens + ref_tokens
        })
        
        print(f"    ğŸ“Š å°è®¡ - Wiki: {wiki_tokens:,}, å‚è€ƒ: {ref_tokens:,}, æ€»è®¡: {wiki_tokens + ref_tokens:,} tokens")
    
    # è®¡ç®—ç±»åˆ«ç»Ÿè®¡
    total_wiki_tokens = sum(stat['wiki_tokens'] for stat in wiki_stats)
    total_ref_tokens = sum(stat['reference_tokens'] for stat in wiki_stats)
    total_tokens = total_wiki_tokens + total_ref_tokens
    
    avg_wiki_tokens = total_wiki_tokens / total_wikis if total_wikis > 0 else 0
    avg_ref_tokens = total_ref_tokens / total_references if total_references > 0 else 0
    
    return {
        'category_name': category_name,
        'total_wikis': total_wikis,
        'total_references': total_references,
        'total_wiki_tokens': total_wiki_tokens,
        'total_reference_tokens': total_ref_tokens,
        'total_tokens': total_tokens,
        'avg_wiki_tokens': avg_wiki_tokens,
        'avg_reference_tokens': avg_ref_tokens,
        'wiki_details': wiki_stats
    }

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description="Calculate tokens for Wiki and reference documents")
    parser.add_argument("--raw-dir", type=str, default="./raw", help="Raw data directory")
    parser.add_argument("--cleaned-dir", type=str, default="./raw_cleaned", help="Cleaned data directory")
    parser.add_argument("--gpu-count", type=int, default=8, help="Number of GPUs/services for load estimation")
    args = parser.parse_args()
    
    print("ğŸ” å¼€å§‹ç»Ÿè®¡Wikiå’Œå‚è€ƒæ–‡çŒ®Tokenæ•°é‡...")
    
    # é…ç½®è·¯å¾„
    raw_dir = args.raw_dir
    cleaned_dir = args.cleaned_dir
    
    # ä½¿ç”¨ç®€åŒ–çš„é…ç½®è€Œéä»è„šæœ¬è§£æ
    oss_config = {
        "gpu_config": f"0-{args.gpu_count-1}",
        "gpu_ids": list(range(args.gpu_count)),
        "ports": list(range(30060, 30060 + args.gpu_count)),
        "service_urls": [f"http://localhost:{port}" for port in range(30060, 30060 + args.gpu_count)],
        "gpu_count": args.gpu_count,
        "internal_ip": "localhost"
    }
    print(f"ğŸŒ OSSæœåŠ¡é…ç½®:")
    print(f"  GPUé…ç½®: {oss_config['gpu_config']}")
    print(f"  ä½¿ç”¨GPU: {oss_config['gpu_ids']}")
    print(f"  æœåŠ¡ç«¯å£: {oss_config['ports']}")
    print(f"  æœåŠ¡æ•°é‡: {oss_config['gpu_count']}")
    print(f"  å†…ç½‘IP: {oss_config['internal_ip']}")
    print()
    
    # é€‰æ‹©æ•°æ®æº
    print("ğŸ“‚ å¯ç”¨çš„æ•°æ®æº:")
    print(f"  1. åŸå§‹æ•°æ®: {raw_dir}")
    print(f"  2. æ¸…æ´—åæ•°æ®: {cleaned_dir}")
    
    use_cleaned = False
    data_dir = raw_dir
    
    # æ£€æŸ¥æ¸…æ´—åç›®å½•æ˜¯å¦å­˜åœ¨
    if os.path.exists(cleaned_dir):
        choice = input("\nğŸ¤” è¯·é€‰æ‹©æ•°æ®æº (1=åŸå§‹æ•°æ®, 2=æ¸…æ´—åæ•°æ®): ").strip()
        if choice == '2':
            use_cleaned = True
            data_dir = cleaned_dir
            print("âœ… ä½¿ç”¨æ¸…æ´—åæ•°æ®")
        else:
            print("âœ… ä½¿ç”¨åŸå§‹æ•°æ®")
    else:
        print("âš ï¸  æ¸…æ´—åç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
    
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # è·å–æ‰€æœ‰ç±»åˆ«ç›®å½•
    categories = []
    for item in os.listdir(data_dir):
        item_path = os.path.join(data_dir, item)
        if os.path.isdir(item_path):
            categories.append(item_path)
    
    if not categories:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç±»åˆ«ç›®å½•")
        return
    
    print(f"\nğŸ“‚ æ‰¾åˆ° {len(categories)} ä¸ªç±»åˆ«")
    for i, cat_path in enumerate(sorted(categories), 1):
        print(f"  {i:2d}. {os.path.basename(cat_path)}")
    print()
    
    # åˆ†ææ¯ä¸ªç±»åˆ«
    all_category_stats = []
    for category_path in sorted(categories):
        print(f"\n{'='*60}")
        stats = analyze_category(category_path, use_cleaned)
        all_category_stats.append(stats)
        print(f"âœ… å®Œæˆç±»åˆ« {stats['category_name']}")
        print(f"   ğŸ“Š {stats['total_wikis']} wikis, {stats['total_references']} references")
        print(f"   ğŸ”¢ Wiki tokens: {stats['total_wiki_tokens']:,}")
        print(f"   ğŸ”¢ å‚è€ƒtokens: {stats['total_reference_tokens']:,}")
        print(f"   ğŸ”¢ æ€»tokens: {stats['total_tokens']:,}")
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    print("\n" + "="*80)
    data_type = "æ¸…æ´—åæ•°æ®" if use_cleaned else "åŸå§‹æ•°æ®"
    print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡ ({data_type})")
    print("="*80)
    
    total_wikis = sum(stats['total_wikis'] for stats in all_category_stats)
    total_references = sum(stats['total_references'] for stats in all_category_stats)
    total_wiki_tokens = sum(stats['total_wiki_tokens'] for stats in all_category_stats)
    total_ref_tokens = sum(stats['total_reference_tokens'] for stats in all_category_stats)
    total_all_tokens = total_wiki_tokens + total_ref_tokens
    
    print(f"ğŸ“‚ æ€»ç±»åˆ«æ•°: {len(all_category_stats)}")
    print(f"ğŸ“„ æ€»Wikiæ•°: {total_wikis:,}")
    print(f"ğŸ“‹ æ€»å‚è€ƒæ–‡çŒ®æ•°: {total_references:,}")
    print()
    print(f"ğŸ”¢ Tokenç»Ÿè®¡:")
    print(f"  Wiki tokens: {total_wiki_tokens:,}")
    print(f"  å‚è€ƒæ–‡çŒ®tokens: {total_ref_tokens:,}")
    print(f"  æ€»tokens: {total_all_tokens:,}")
    print()
    print(f"ğŸ“Š å¹³å‡å€¼:")
    print(f"  æ¯ä¸ªWikiå¹³å‡tokens: {total_wiki_tokens/total_wikis:,.1f}" if total_wikis > 0 else "  æ¯ä¸ªWikiå¹³å‡tokens: 0")
    print(f"  æ¯ä¸ªå‚è€ƒæ–‡çŒ®å¹³å‡tokens: {total_ref_tokens/total_references:,.1f}" if total_references > 0 else "  æ¯ä¸ªå‚è€ƒæ–‡çŒ®å¹³å‡tokens: 0")
    print(f"  æ¯ä¸ªWiki(å«å‚è€ƒæ–‡çŒ®)å¹³å‡tokens: {total_all_tokens/total_wikis:,.1f}" if total_wikis > 0 else "  æ¯ä¸ªWiki(å«å‚è€ƒæ–‡çŒ®)å¹³å‡tokens: 0")
    print()
    print(f"ğŸŒ OSSæœåŠ¡å¤„ç†èƒ½åŠ›è¯„ä¼°:")
    tokens_per_service = total_all_tokens / oss_config['gpu_count']
    print(f"  æ¯ä¸ªOSSæœåŠ¡å¹³å‡å¤„ç†tokens: {tokens_per_service:,.1f}")
    print(f"  æœåŠ¡URLç¤ºä¾‹:")
    for i, url in enumerate(oss_config['service_urls'][:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
        print(f"    æœåŠ¡{i}: {url}")
    if len(oss_config['service_urls']) > 3:
        print(f"    ... ä»¥åŠå…¶ä»– {len(oss_config['service_urls']) - 3} ä¸ªæœåŠ¡")
    
    # æŒ‰ç±»åˆ«æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
    print("\n" + "="*80)
    print("ğŸ“Š å„ç±»åˆ«è¯¦ç»†ç»Ÿè®¡")
    print("="*80)
    
    # æŒ‰æ€»tokenæ•°æ’åº
    sorted_stats = sorted(all_category_stats, key=lambda x: x['total_tokens'], reverse=True)
    
    for i, stats in enumerate(sorted_stats, 1):
        print(f"\n{i:2d}. ğŸ“ {stats['category_name']}:")
        print(f"     ğŸ“„ Wikiæ•°: {stats['total_wikis']}")
        print(f"     ğŸ“‹ å‚è€ƒæ–‡çŒ®æ•°: {stats['total_references']}")
        print(f"     ğŸ”¢ Wiki tokens: {stats['total_wiki_tokens']:,}")
        print(f"     ğŸ”¢ å‚è€ƒæ–‡çŒ®tokens: {stats['total_reference_tokens']:,}")
        print(f"     ğŸ”¢ æ€»tokens: {stats['total_tokens']:,}")
        print(f"     ğŸ“Š å¹³å‡Wiki tokens: {stats['avg_wiki_tokens']:,.1f}")
        if stats['total_references'] > 0:
            print(f"     ğŸ“Š å¹³å‡å‚è€ƒæ–‡çŒ®tokens: {stats['avg_reference_tokens']:,.1f}")
        
        # è®¡ç®—è¯¥ç±»åˆ«å æ€»ä½“çš„æ¯”ä¾‹
        percentage = (stats['total_tokens'] / total_all_tokens * 100) if total_all_tokens > 0 else 0
        print(f"     ğŸ“ˆ å æ€»ä½“æ¯”ä¾‹: {percentage:.1f}%")
    
    # æ‰¾å‡ºtokenæ•°æœ€å¤šå’Œæœ€å°‘çš„wiki
    all_wiki_details = []
    for category_stats in all_category_stats:
        for wiki_detail in category_stats['wiki_details']:
            wiki_detail['category'] = category_stats['category_name']
            all_wiki_details.append(wiki_detail)
    
    if all_wiki_details:
        print("\n" + "="*80)
        print("ğŸ† Tokenæ•°é‡æ’è¡Œ")
        print("="*80)
        
        # æŒ‰æ€»tokenæ•°æ’åº
        sorted_wikis = sorted(all_wiki_details, key=lambda x: x['total_tokens'], reverse=True)
        
        print("ğŸ¥‡ Tokenæ•°æœ€å¤šçš„å‰10ä¸ªWiki:")
        for i, wiki in enumerate(sorted_wikis[:10], 1):
            print(f"  {i:2d}. [{wiki['category']}] {wiki['name']}")
            print(f"      æ€»è®¡: {wiki['total_tokens']:,} tokens")
            print(f"      (Wiki: {wiki['wiki_tokens']:,}, å‚è€ƒ: {wiki['reference_tokens']:,}, å‚è€ƒæ–‡ä»¶: {wiki['reference_count']})")
        
        print("\nğŸ“Š Tokenæ•°åˆ†å¸ƒç»Ÿè®¡:")
        token_counts = [wiki['total_tokens'] for wiki in all_wiki_details]
        print(f"  æœ€å¤§å€¼: {max(token_counts):,} tokens")
        print(f"  æœ€å°å€¼: {min(token_counts):,} tokens")
        print(f"  ä¸­ä½æ•°: {statistics.median(token_counts):,.1f} tokens")
        if len(token_counts) > 1:
            print(f"  æ ‡å‡†å·®: {statistics.stdev(token_counts):,.1f} tokens")
        
        # åˆ†å¸ƒåŒºé—´ç»Ÿè®¡
        ranges = [
            (0, 1000, "< 1K"),
            (1000, 5000, "1K-5K"),
            (5000, 10000, "5K-10K"),
            (10000, 50000, "10K-50K"),
            (50000, 100000, "50K-100K"),
            (100000, float('inf'), "> 100K")
        ]
        
        print(f"\nğŸ“ˆ Tokenæ•°åˆ†å¸ƒåŒºé—´:")
        for min_val, max_val, label in ranges:
            count = sum(1 for tokens in token_counts if min_val <= tokens < max_val)
            percentage = (count / len(token_counts) * 100) if token_counts else 0
            print(f"  {label:>8}: {count:3d} wikis ({percentage:4.1f}%)")
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡åˆ°JSONæ–‡ä»¶
    output_file = os.path.join(data_dir, f"token_statistics_{'cleaned' if use_cleaned else 'raw'}.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "data_source": {
                "type": "cleaned" if use_cleaned else "raw",
                "directory": data_dir,
                "description": data_type
            },
            "oss_config": oss_config,
            "summary": {
                "total_categories": len(all_category_stats),
                "total_wikis": total_wikis,
                "total_references": total_references,
                "total_wiki_tokens": total_wiki_tokens,
                "total_reference_tokens": total_ref_tokens,
                "total_all_tokens": total_all_tokens,
                "avg_wiki_tokens": total_wiki_tokens/total_wikis if total_wikis > 0 else 0,
                "avg_reference_tokens": total_ref_tokens/total_references if total_references > 0 else 0,
                "avg_tokens_per_wiki_with_refs": total_all_tokens/total_wikis if total_wikis > 0 else 0,
                "tokens_per_oss_service": total_all_tokens / oss_config['gpu_count']
            },
            "category_stats": all_category_stats,
            "top_wikis": sorted_wikis[:50] if 'sorted_wikis' in locals() else [],
            "statistics": {
                "max_tokens": max(token_counts) if 'token_counts' in locals() and token_counts else 0,
                "min_tokens": min(token_counts) if 'token_counts' in locals() and token_counts else 0,
                "median_tokens": statistics.median(token_counts) if 'token_counts' in locals() and token_counts else 0,
                "stdev_tokens": statistics.stdev(token_counts) if 'token_counts' in locals() and len(token_counts) > 1 else 0
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»Ÿè®¡å·²ä¿å­˜åˆ°: {output_file}")
    print(f"\nğŸ¯ æ•°æ®å¤„ç†æ‘˜è¦:")
    print(f"  æ•°æ®ç±»å‹: {data_type}")
    print(f"  æ•°æ®ç›®å½•: {data_dir}")
    print(f"  å‚è€ƒæ–‡çŒ®ç›®å½•: {'reference_pages_cleaned' if use_cleaned else 'reference_pages'}")
    print(f"  OSSæœåŠ¡æ•°é‡: {oss_config['gpu_count']}")
    print(f"  æ¯æœåŠ¡å¹³å‡è´Ÿè½½: {tokens_per_service:,.1f} tokens")
    print("\nğŸ‰ ç»Ÿè®¡å®Œæˆï¼")

if __name__ == "__main__":
    main()