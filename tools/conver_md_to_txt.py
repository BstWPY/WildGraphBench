#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Convert Markdown to TXT - Batch Processing

"""
æ‰¹é‡è½¬æ¢æ‰€æœ‰åˆ†ç±»çš„ reference Markdown æ–‡ä»¶ä¸º TXT

åŠŸèƒ½:
  1. éåŽ† dataset ä¸‹æ‰€æœ‰åˆ†ç±»
  2. å°†æ¯ä¸ªä¸»é¢˜çš„ reference_pages/*.md è½¬æ¢ä¸º .txt
  3. ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆ merged.txtï¼ˆæ‰€æœ‰ reference æ‹¼æŽ¥ï¼‰
"""

import os
from pathlib import Path
from typing import Dict

# é…ç½® - ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œå¯é€šè¿‡çŽ¯å¢ƒå˜é‡è¦†ç›–
DATASET_ROOT = Path(os.environ.get("DATASET_ROOT", "./corpus"))
OUTPUT_ROOT = Path(os.environ.get("OUTPUT_ROOT", "./txt_output"))

# æŽ’é™¤çš„ç›®å½•
SKIP_DIRS = {"token_statistics_raw.json"}


def convert_topic_references(
    category_name: str,
    topic_name: str,
    ref_pages_dir: Path,
    output_dir: Path
) -> Dict[str, int]:
    """è½¬æ¢å•ä¸ªä¸»é¢˜çš„ reference pages
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯ {'converted': è½¬æ¢æ•°, 'skipped': è·³è¿‡æ•°, 'total_chars': æ€»å­—ç¬¦æ•°}
    """
    stats = {'converted': 0, 'skipped': 0, 'total_chars': 0}
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    txt_files_dir = output_dir / "txt_files"
    txt_files_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–æ‹¼æŽ¥å†…å®¹
    merged_content = ""
    
    # è½¬æ¢æ‰€æœ‰ .md æ–‡ä»¶
    md_files = sorted(ref_pages_dir.glob("*.md"))
    
    if not md_files:
        print(f"  âš ï¸  æœªæ‰¾åˆ°ä»»ä½• .md æ–‡ä»¶")
        return stats
    
    for md_file in md_files:
        try:
            # è¯»å– .md æ–‡ä»¶å†…å®¹
            content = md_file.read_text(encoding="utf-8")
            
            # å†™å…¥åˆ° .txt æ–‡ä»¶
            txt_file = txt_files_dir / md_file.name.replace(".md", ".txt")
            txt_file.write_text(content, encoding="utf-8")
            
            # æ·»åŠ åˆ°æ‹¼æŽ¥å†…å®¹
            merged_content += content + "\n"
            
            stats['converted'] += 1
            stats['total_chars'] += len(content)
            
        except Exception as e:
            print(f"    âŒ è½¬æ¢å¤±è´¥ {md_file.name}: {e}")
            stats['skipped'] += 1
    
    # å†™å…¥æ‹¼æŽ¥åŽçš„æ–‡ä»¶
    merged_file = output_dir / "merged.txt"
    merged_file.write_text(merged_content, encoding="utf-8")
    
    return stats


def main():
    print("="*60)
    print("ðŸš€ æ‰¹é‡è½¬æ¢ MD â†’ TXT")
    print("="*60)
    print()
    
    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)
    
    # å…¨å±€ç»Ÿè®¡
    global_stats = {
        'total_categories': 0,
        'total_topics': 0,
        'total_files': 0,
        'total_chars': 0,
        'failed_topics': 0,
    }
    
    # éåŽ†æ‰€æœ‰åˆ†ç±»
    for category_dir in sorted(DATASET_ROOT.iterdir()):
        if not category_dir.is_dir():
            continue
        
        category_name = category_dir.name
        
        # è·³è¿‡ç‰¹å®šç›®å½•
        if category_name in SKIP_DIRS:
            print(f"â­ï¸  è·³è¿‡: {category_name}")
            continue
        
        global_stats['total_categories'] += 1
        
        print(f"\n{'='*60}")
        print(f"ðŸ“‚ åˆ†ç±»: {category_name}")
        print(f"{'='*60}")
        
        # éåŽ†è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰ä¸»é¢˜
        topic_count = 0
        for topic_dir in sorted(category_dir.iterdir()):
            if not topic_dir.is_dir():
                continue
            
            topic_name = topic_dir.name
            
            # æ£€æŸ¥ reference_pages ç›®å½•
            ref_pages_dir = topic_dir / "reference" / "reference_pages"
            if not ref_pages_dir.exists():
                print(f"  â­ï¸  è·³è¿‡ {topic_name}: æ—  reference_pages ç›®å½•")
                continue
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = OUTPUT_ROOT / category_name / topic_name
            
            print(f"\n  [{topic_count + 1}] {topic_name}")
            
            # è½¬æ¢
            try:
                stats = convert_topic_references(
                    category_name,
                    topic_name,
                    ref_pages_dir,
                    output_dir
                )
                
                if stats['converted'] > 0:
                    topic_count += 1
                    global_stats['total_topics'] += 1
                    global_stats['total_files'] += stats['converted']
                    global_stats['total_chars'] += stats['total_chars']
                    
                    # æ ¼å¼åŒ–å­—ç¬¦æ•°
                    chars_mb = stats['total_chars'] / 1_000_000
                    
                    print(f"    âœ… è½¬æ¢ {stats['converted']} ä¸ªæ–‡ä»¶")
                    print(f"    ðŸ“„ æ€»å­—ç¬¦æ•°: {stats['total_chars']:,} ({chars_mb:.2f} MB)")
                    print(f"    ðŸ“ è¾“å‡º: {output_dir}")
                else:
                    global_stats['failed_topics'] += 1
                
            except Exception as e:
                print(f"    âŒ å¤±è´¥: {e}")
                global_stats['failed_topics'] += 1
        
        if topic_count > 0:
            print(f"\n  âœ… {category_name}: å¤„ç† {topic_count} ä¸ªä¸»é¢˜")
    
    # æ‰“å°å…¨å±€ç»Ÿè®¡
    print("\n" + "="*60)
    print("âœ… è½¬æ¢å®Œæˆï¼")
    print("="*60)
    print()
    print("ðŸ“Š å…¨å±€ç»Ÿè®¡:")
    print(f"  åˆ†ç±»æ•°: {global_stats['total_categories']}")
    print(f"  ä¸»é¢˜æ•°: {global_stats['total_topics']}")
    print(f"  è½¬æ¢æ–‡ä»¶æ•°: {global_stats['total_files']}")
    print(f"  æ€»å­—ç¬¦æ•°: {global_stats['total_chars']:,} ({global_stats['total_chars'] / 1_000_000:.2f} MB)")
    print(f"  å¤±è´¥ä¸»é¢˜æ•°: {global_stats['failed_topics']}")
    print()
    print(f"ðŸ“ è¾“å‡ºç›®å½•: {OUTPUT_ROOT}")
    
    # ç”Ÿæˆç›®å½•æ ‘
    print("\nðŸ“‚ è¾“å‡ºç›®å½•ç»“æž„:")
    for category_dir in sorted(OUTPUT_ROOT.iterdir()):
        if category_dir.is_dir():
            topic_dirs = [d for d in category_dir.iterdir() if d.is_dir()]
            print(f"  {category_dir.name}/ ({len(topic_dirs)} ä¸ªä¸»é¢˜)")
            for topic_dir in sorted(topic_dirs)[:3]:  # åªæ˜¾ç¤ºå‰ 3 ä¸ª
                txt_count = len(list((topic_dir / "txt_files").glob("*.txt")))
                merged_file = topic_dir / "merged.txt"
                merged_size = merged_file.stat().st_size if merged_file.exists() else 0
                print(f"    â”œâ”€ {topic_dir.name}/ ({txt_count} ä¸ª TXT, merged: {merged_size:,} bytes)")
            if len(topic_dirs) > 3:
                print(f"    â””â”€ ... è¿˜æœ‰ {len(topic_dirs) - 3} ä¸ªä¸»é¢˜")


if __name__ == "__main__":
    main()