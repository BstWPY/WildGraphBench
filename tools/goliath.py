import json
import time
import requests
import logging
import base64
import random
import os
import re
from typing import Dict, Any, Optional

# Default configuration - users should set their own API URL
# You can use Jina AI Reader API (https://jina.ai/reader) or similar services
DEFAULT_SPIDER_API_URL = os.environ.get("SPIDER_API_URL", "YOUR_SPIDER_API_URL_HERE")
DEFAULT_SPIDER_TIMEOUT = 120
DEFAULT_MAX_RETRY = 2

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger('SpiderTool')
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)


class SpiderTool:
    """åŸºäºspider-api-gatewayçš„ç½‘é¡µçˆ¬å–å·¥å…·"""

    def __init__(
        self,
        api_url: str = DEFAULT_SPIDER_API_URL,
        timeout: int = DEFAULT_SPIDER_TIMEOUT,
        max_retry: int = DEFAULT_MAX_RETRY,
        enable_cache: bool = True,
        enable_oversea: bool = True,
        debug: bool = False,
    ):
        self.api_url = api_url
        self.timeout = timeout
        self.max_retry = max_retry
        self.enable_cache = enable_cache
        self.enable_oversea = enable_oversea
        self.debug = debug

    def retrieve(
        self,
        url: str,
        content: str = "string",  # é»˜è®¤å€¼ï¼Œå¯ä»¥è‡ªå®šä¹‰
    ) -> Dict[str, Any]:
        """
        çˆ¬å–å’Œè§£æç½‘é¡µå†…å®¹

        Args:
            url: è¦çˆ¬å–çš„ç½‘å€
            content: å†…å®¹å‚æ•°ï¼ˆæ ¹æ®APIæ–‡æ¡£è°ƒæ•´ï¼‰

        Returns:
            åŒ…å«çˆ¬å–ç»“æœçš„å­—å…¸
        """
        for attempt in range(self.max_retry):
            request_id = (
                f"spider_retrieve_{int(time.time() * 1000)}_{random.randint(1000, 9999)}"
            )

            # æ ¹æ®curlå‘½ä»¤æ„å»ºpayload
            payload = {
                "content": content,
                "enable_cache": self.enable_cache,
                "enable_oversea": self.enable_oversea,
                "url": url,
            }

            headers = {
                "accept": "application/json",
                "Content-Type": "application/json",
            }

            try:
                logger.info(f"æ­£åœ¨çˆ¬å–: {url}")
                if self.debug:
                    logger.debug(
                        f"è¯·æ±‚è½½è·: {json.dumps(payload, ensure_ascii=False, indent=2)}"
                    )
                    logger.debug(
                        f"è¯·æ±‚å¤´: {json.dumps(headers, ensure_ascii=False, indent=2)}"
                    )

                response = requests.post(
                    self.api_url,
                    json=payload,  # ä½¿ç”¨jsonå‚æ•°è€Œä¸æ˜¯data
                    headers=headers,
                    timeout=self.timeout,
                )

                if self.debug:
                    logger.debug(f"HTTPçŠ¶æ€ç : {response.status_code}")
                    logger.debug(f"å“åº”å¤´: {dict(response.headers)}")

                return self._handle_response(response, url, request_id)

            except requests.exceptions.Timeout as e:
                logger.error(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retry}): {e}")
                if attempt < self.max_retry - 1:
                    wait_time = 2 ** attempt + random.uniform(0, 1)  # æŒ‡æ•°é€€é¿
                    logger.info(f"ç­‰å¾… {wait_time:.1f}s åé‡è¯•...")
                    time.sleep(wait_time)
                continue

            except requests.exceptions.ConnectionError as e:
                logger.error(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retry}): {e}")
                if attempt < self.max_retry - 1:
                    wait_time = 2 ** attempt + random.uniform(0, 1)
                    logger.info(f"ç­‰å¾… {wait_time:.1f}s åé‡è¯•...")
                    time.sleep(wait_time)
                continue

            except Exception as e:
                logger.error(
                    f"å…¶ä»–é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retry}): {type(e).__name__}: {e}"
                )
                if attempt < self.max_retry - 1:
                    wait_time = 2 ** attempt + random.uniform(0, 1)
                    logger.info(f"ç­‰å¾… {wait_time:.1f}s åé‡è¯•...")
                    time.sleep(wait_time)
                continue

        return {
            "success": False,
            "error": f"æ‰€æœ‰ {self.max_retry} æ¬¡é‡è¯•å°è¯•å‡å¤±è´¥",
            "url": url,
        }

    def _handle_response(
        self,
        response: requests.Response,
        url: str,
        request_id: str,
    ) -> Dict[str, Any]:
        """å¤„ç†å“åº”ï¼Œè¾“å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯"""
        try:
            # é¦–å…ˆæ£€æŸ¥HTTPçŠ¶æ€ç 
            if response.status_code != 200:
                error_msg = f"HTTPé”™è¯¯: {response.status_code} - {response.reason}"
                if self.debug:
                    logger.error(f"å“åº”å†…å®¹: {response.text}")
                return {
                    "success": False,
                    "error": error_msg,
                    "http_status": response.status_code,
                    "response_text": response.text,
                    "url": url,
                    "request_id": request_id,
                }

            # å°è¯•è§£æJSON
            try:
                response_data = response.json()
            except json.JSONDecodeError as e:
                error_msg = f"JSONè§£æå¤±è´¥: {e}"
                logger.error(f"{error_msg}, åŸå§‹å“åº”: {response.text[:1000]}")
                return {
                    "success": False,
                    "error": error_msg,
                    "response_text": response.text,
                    "url": url,
                    "request_id": request_id,
                }

            # æ‰“å°å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
            if self.debug:
                logger.debug(
                    f"å®Œæ•´APIå“åº”: {json.dumps(response_data, ensure_ascii=False, indent=2)}"
                )

            # åˆ†æå“åº”ç»“æ„
            response_keys = list(response_data.keys())
            logger.info(f"å“åº”åŒ…å«å­—æ®µ: {response_keys}")

            # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸï¼ˆæ ¹æ®å®é™…APIå“åº”æ ¼å¼è°ƒæ•´ï¼‰
            success_indicators = [
                response_data.get("success") is True,
                response_data.get("status") == "success",
                response_data.get("code") == 200,
                "data" in response_data,
                "content" in response_data,
                "result" in response_data,
            ]

            if any(success_indicators):
                # æå–å†…å®¹ï¼ˆæ ¹æ®å®é™…APIå“åº”æ ¼å¼è°ƒæ•´å­—æ®µåï¼‰
                content = ""
                title = ""
                description = ""

                # å°è¯•ä¸åŒçš„å­—æ®µå
                if "data" in response_data:
                    data_field = response_data["data"]
                    if isinstance(data_field, dict):
                        content = (
                            data_field.get("content", "")
                            or data_field.get("text", "")
                            or data_field.get("markdown", "")
                        )
                        title = data_field.get("title", "")
                        description = data_field.get("description", "")
                    elif isinstance(data_field, str):
                        content = data_field

                elif "content" in response_data:
                    content = response_data["content"]
                    title = response_data.get("title", "")
                    description = response_data.get("description", "")

                elif "result" in response_data:
                    result_field = response_data["result"]
                    if isinstance(result_field, dict):
                        content = result_field.get("content", "") or result_field.get(
                            "text", ""
                        )
                        title = result_field.get("title", "")
                        description = result_field.get("description", "")
                    elif isinstance(result_field, str):
                        content = result_field

                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰å†…å®¹ï¼Œå°è¯•ç›´æ¥ä»å“åº”ä¸­æå–
                if not content:
                    for key in ["text", "markdown", "html"]:
                        if key in response_data and response_data[key]:
                            content = response_data[key]
                            break

                logger.info(f"âœ… æˆåŠŸæå–å†…å®¹ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")

                return {
                    "success": True,
                    "result": {
                        "content": content,
                        "title": title,
                        "description": description,
                        "url": url,
                    },
                    "request_id": request_id,
                    "raw_response_keys": response_keys,
                    "url": url,
                }

            # å¤±è´¥æƒ…å†µ
            error_details = []

            # æ£€æŸ¥å¸¸è§çš„é”™è¯¯å­—æ®µ
            if "error" in response_data:
                error_details.append(f"APIé”™è¯¯: {response_data['error']}")
            if "message" in response_data:
                error_details.append(f"æ¶ˆæ¯: {response_data['message']}")
            if "status" in response_data:
                error_details.append(f"çŠ¶æ€: {response_data['status']}")
            if "code" in response_data:
                error_details.append(f"é”™è¯¯ä»£ç : {response_data['code']}")

            # ç»„åˆé”™è¯¯ä¿¡æ¯
            if error_details:
                error_msg = "APIè¿”å›å¤±è´¥çŠ¶æ€: " + " | ".join(error_details)
            else:
                error_msg = f"æœªçŸ¥çš„APIå“åº”æ ¼å¼ï¼Œå“åº”å­—æ®µ: {response_keys}"

            # å¦‚æœå“åº”å¾ˆå°ï¼ŒåŒ…å«å®Œæ•´å†…å®¹
            if len(str(response_data)) < 2000:
                error_msg += f" | å®Œæ•´å“åº”: {json.dumps(response_data, ensure_ascii=False)}"

            logger.error(error_msg)

            return {
                "success": False,
                "error": error_msg,
                "raw_response": response_data,
                "response_keys": response_keys,
                "url": url,
                "request_id": request_id,
            }

        except Exception as e:
            error_msg = f"è§£æå“åº”æ—¶å‡ºé”™: {type(e).__name__}: {e}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "raw_text": response.text,
                "url": url,
                "request_id": request_id,
            }

    def __call__(self, url: str, **kwargs) -> Dict[str, Any]:
        """
        è°ƒç”¨æ¥å£çš„ç®€åŒ–æ–¹æ³•

        Args:
            url: è¦çˆ¬å–çš„ç½‘å€
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            çˆ¬å–ç»“æœ
        """
        try:
            response_dict = self.retrieve(url, **kwargs)
            if response_dict.get("success"):
                result = response_dict.get("result", {})
                return {
                    'success': True,
                    'url': result.get("url", url),
                    'title': result.get("title", ""),
                    'description': result.get("description", ""),
                    'content': result.get("content", ""),
                    'request_id': response_dict.get("request_id", "")
                }
            else:
                return {
                    'success': False,
                    'url': url,
                    'title': '',
                    'content': '',
                    'error': response_dict.get("error", "Unknown error"),
                    'request_id': response_dict.get("request_id", "")
                }
        except Exception as e:
            logger.error(f"çˆ¬å–å¤±è´¥: {e}")
            return {
                'success': False,
                'url': url,
                'title': '',
                'content': '',
                'error': f"è°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}"
            }


def build_default_spider_tool(debug: bool = False) -> SpiderTool:
    """æä¾›ä¸€ä¸ªå¯å¤ç”¨çš„é»˜è®¤å®ä¾‹"""
    return SpiderTool(
        api_url=DEFAULT_SPIDER_API_URL,
        timeout=DEFAULT_SPIDER_TIMEOUT,
        max_retry=DEFAULT_MAX_RETRY,
        enable_cache=True,
        enable_oversea=True,
        debug=debug,
    )


def test_spider_api():
    """æµ‹è¯•æ–°çš„spider API"""
    test_urls = [
        "https://en.wikipedia.org/wiki/ChatGPT",
    ]

    print("ğŸš€ æµ‹è¯•Spider API...")

    # åˆ›å»ºå·¥å…·å®ä¾‹
    tool = SpiderTool(debug=True)

    success_count = 0
    total_count = len(test_urls)

    for i, url in enumerate(test_urls, 1):
        print("\n" + "=" * 80)
        print(f"ğŸ“‹ æµ‹è¯• {i}/{total_count}: {url}")
        print("=" * 80)

        start_time = time.time()
        result = tool(url)
        end_time = time.time()

        if result.get("success"):
            content_len = len(result.get("content", ""))
            print("âœ… æˆåŠŸï¼")
            print(f"   æ ‡é¢˜: {result.get('title', 'N/A')}")
            print(f"   å†…å®¹é•¿åº¦: {content_len} å­—ç¬¦")
            print(f"   è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"   å†…å®¹é¢„è§ˆ: {result.get('content', '')[:200]}...")
            success_count += 1
        else:
            error = result.get("error", "Unknown error")
            print(f"âŒ å¤±è´¥: {error}")
            print(f"   è€—æ—¶: {end_time - start_time:.2f}ç§’")

        # åœ¨URLä¹‹é—´æ·»åŠ å»¶è¿Ÿ
        if i < total_count:
            print("â³ ç­‰å¾…2ç§’...")
            time.sleep(2)

    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼æˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")


# ä¿æŒå…¼å®¹æ€§ï¼šä¸ºäº†è®©æ—§ä»£ç ä»ç„¶å·¥ä½œï¼Œæä¾›åˆ«å
GoliathTool = SpiderTool
build_default_goliath_tool = build_default_spider_tool


if __name__ == "__main__":
    print("=== æµ‹è¯•æ–°çš„Spider APIç½‘é¡µçˆ¬å–åŠŸèƒ½ ===")

    # ç›´æ¥æµ‹è¯•å•ä¸ªURL
    tool = build_default_spider_tool(debug=True)
    result = tool("https://www.bbc.co.uk/pressoffice/pressreleases/stories/2008/03_march/07/ob.shtml")

    print("\nğŸ“Š å•ä¸ªURLæµ‹è¯•ç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if result.get("success"):
        output_dir = os.environ.get("SPIDER_OUTPUT_DIR", "./output")
        os.makedirs(output_dir, exist_ok=True)

        title = result.get("title", "untitled").replace("/", "_").replace("\\", "_")
        content = result.get("content", "")

        filename = f"spider_test_{title}.md"
        filepath = os.path.join(output_dir, filename)

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# {result.get('title', 'Untitled')}\n\n")
            f.write(f"**URL**: {result.get('url', '')}\n\n")
            f.write(f"**Description**: {result.get('description', '')}\n\n")
            f.write("---\n\n")
            f.write(content)

        print(f"âœ… å†…å®¹å·²ä¿å­˜åˆ°: {filepath}")

    print("\n" + "=" * 80)
    test_spider_api()
